{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Machine Learning, with Application in Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Paul Paczuski [pavopax.com](http://pavopax.com)*\n",
    "\n",
    "*Instructions: This is a Jupyter Notebook. If opened with \"Launch Binder\" (or running on your local machine), then use `shift-Enter` to run the code cells and see the output.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How can we use a *machine* to *learn* to solve a task (recognize handwritten digits)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![eight](digit.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The above is a handwritten digit, converted to a computer-readable format. Which digit do you think this is?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this machine learning demo, our objective is:\n",
    "* Given images of handwritten digits, ask the machine to tell us what digits are shown\n",
    "\n",
    "The steps in the process:\n",
    "* Read in the raw data\n",
    "* Learn the pattern (**fit a model**) using a bunch of known digit images and their labels (**training data**)\n",
    "* Use the learned pattern on new data, to determine what digits are shown (**predict**)\n",
    "\n",
    "We can perform this task with just a few lines of Python scikit-learn code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optical Recognition of Handwritten Digits Data Set\n",
      "===================================================\n",
      "\n",
      "Notes\n",
      "-----\n",
      "Data Set Characteristics:\n",
      "    :Number of Instances: 5620\n",
      "    :Number of Attributes: 64\n",
      "    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\n",
      "    :Missing Attribute Values: None\n",
      "    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\n",
      "    :Date: July; 1998\n",
      "\n",
      "This is a copy of the test set of the UCI ML hand-written digits datasets\n",
      "http://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
      "\n",
      "The data set contains images of hand-written digits: 10 classes where\n",
      "each class refers to a digit.\n",
      "\n",
      "Preprocessing programs made available by NIST were used to extract\n",
      "normalized bitmaps of handwritten digits from a preprinted form. From a\n",
      "total of 43 people, 30 contributed to the training set and different 13\n",
      "to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\n",
      "4x4 and the number of on pixels are counted in each block. This generates\n",
      "an input matrix of 8x8 where each element is an integer in the range\n",
      "0..16. This reduces dimensionality and gives invariance to small\n",
      "distortions.\n",
      "\n",
      "For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\n",
      "T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\n",
      "L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\n",
      "1994.\n",
      "\n",
      "References\n",
      "----------\n",
      "  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\n",
      "    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\n",
      "    Graduate Studies in Science and Engineering, Bogazici University.\n",
      "  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\n",
      "  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\n",
      "    Linear dimensionalityreduction using relevance weighted LDA. School of\n",
      "    Electrical and Electronic Engineering Nanyang Technological University.\n",
      "    2005.\n",
      "  - Claudio Gentile. A New Approximate Maximal Margin Classification\n",
      "    Algorithm. NIPS. 2000.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# set-up and load data\n",
    "from sklearn import datasets\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "print digits.DESCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we have 1797 examples, each consisting of a matrix of 64 elements\n",
    "digits.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   0.,   0.,   2.,  13.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         8.,  15.,   0.,   0.,   0.,   0.,   0.,   5.,  16.,   5.,   2.,\n",
       "         0.,   0.,   0.,   0.,  15.,  12.,   1.,  16.,   4.,   0.,   0.,\n",
       "         4.,  16.,   2.,   9.,  16.,   8.,   0.,   0.,   0.,  10.,  14.,\n",
       "        16.,  16.,   4.,   0.,   0.,   0.,   0.,   0.,  13.,   8.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,  13.,   6.,   0.,   0.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here is one random \"image\"\n",
    "digits.data[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ... it is labeled as the digit \"4\"\n",
    "digits.target[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 ..., 8 9 8]\n"
     ]
    }
   ],
   "source": [
    "# \"target\" is ML speak for outcome (y)\n",
    "# our target is the digit labels 0-9\n",
    "digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1797\n"
     ]
    }
   ],
   "source": [
    "len(digits.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the Model \n",
    "This is the \"learn\" part (Machine *Learning*).\n",
    "\n",
    "We'll use a machine learning algorithm to find the patterns in this data (\"fit the model\").\n",
    "\n",
    "We want to learn this relationship:\n",
    "\n",
    "    Given a matrix of numbers -> which digit is it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# let's pull out some black box algorithm to do the \"learning\"\n",
    "from sklearn import svm\n",
    "\n",
    "classifier = svm.SVC(gamma=0.001, C=100.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma=0.001, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now, FIT the model (learn the pattern of the data)\n",
    "# (this .fit method \"changes\" the object \"classifier\")\n",
    "classifier.fit(digits.data[:-1], digits.target[:-1])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the Model for Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can predict new values.\n",
    "\n",
    "In particular, we can ask our classifier (algorithm) what is the digit of our last image in the digits dataset (\"-1\" means last - ignore the semicolon), which we have not used to train the classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.   0.  10.  14.   8.   1.   0.   0.   0.   2.  16.  14.   6.   1.\n",
      "    0.   0.   0.   0.  15.  15.   8.  15.   0.   0.   0.   0.   5.  16.\n",
      "   16.  10.   0.   0.   0.   0.  12.  15.  15.  12.   0.   0.   0.   4.\n",
      "   16.   6.   4.  16.   6.   0.   0.   8.  16.  10.   8.  16.   8.   0.\n",
      "    0.   1.   8.  12.  14.  12.   1.   0.]]\n"
     ]
    }
   ],
   "source": [
    "digits.data[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the algorithm's answer (prediction) is...\n",
    "classifier.predict(digits.data[-1:])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![eight](digit.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you think?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary \n",
    "\n",
    "Here are the key steps in this process:\n",
    "\n",
    "1. Read in the data\n",
    "2. **Fit** the model using some algorithms\n",
    "3.  Use the model to **predict** on new data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two Types of Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the main types of machine learning, as well as some example algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Learning\n",
    "- When the target/outcome/y is known\n",
    "- There are two classes of models, depending on the type of the target:\n",
    "    - classification: when outcome is categorical\n",
    "    - regression: when outcome is continuous\n",
    "- **Example algorithms**: linear regression, logistic regression, support vector machine, random forest, k-nearest neighbors\n",
    "\n",
    "## Unsupervised Learning\n",
    "- When the target/outcome/y is unknown (we want to find \"clusters\" in the data)\n",
    "- There are two main uses of unsupervised learning:\n",
    "  - clustering\n",
    "  - dimension reduction\n",
    "- **Example algorithms**: k-means clustering, affinity propagation clustering, principal component analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resources\n",
    "\n",
    "## Essential quick-starts\n",
    "\n",
    "[Machine learning introduction/tutorial (with scikit-learn code)](http://scikit-learn.org/stable/tutorial/basic/tutorial.html)\n",
    "\n",
    "[Python - \"immediately useful tools\"](http://python.net/~goodger/projects/pycon/2007/idiomatic/handout.html)\n",
    "\n",
    "[10 minutes to Pandas](http://pandas.pydata.org/pandas-docs/stable/10min.html)\n",
    "\n",
    "[Pandas cookbook](http://pandas.pydata.org/pandas-docs/stable/cookbook.html)\n",
    "\n",
    "[Pandas cheat sheet](blog.quandl.com/cheat-sheet-for-data-analysis-in-python)\n",
    "\n",
    "\n",
    "## More Tutorials\n",
    "\n",
    "[Supervised learning introduction (with scikit-learn code)](http://scikit-learn.org/stable/tutorial/statistical_inference/supervised_learning.html)\n",
    "\n",
    "[Unsupervised learning introduction (with scikit-learn code)](http://scikit-learn.org/stable/tutorial/statistical_inference/unsupervised_learning.html)\n",
    "\n",
    "## References\n",
    "\n",
    "A great textbook to learn more - highly recommended:\n",
    "\n",
    "* [[free pdf!] An Introduction to Statistical Learning with Applications in R](http://www-bcf.usc.edu/~gareth/ISL/)\n",
    "\n",
    "This is the Canonical Textbook on Machine Learning, by the same authors, but it is older than the above book and is more technical\n",
    "\n",
    "* [[free pdf!] The Elements of Statistical Learning: Data Mining, Inference, and Prediction](http://statweb.stanford.edu/~tibs/ElemStatLearn/)\n",
    "\n",
    "\n",
    "[scikit-learn tutorials](http://scikit-learn.org/stable/tutorial/index.html)\n",
    "\n",
    "[scikit-learn user guide](http://scikit-learn.org/stable/user_guide.html)\n",
    "\n",
    "[Choosing the right estimator](http://scikit-learn.org/stable/tutorial/machine_learning_map/index.html)\n",
    "\n",
    "[scikit-learn - documentation](http://scikit-learn.org/stable/documentation.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acknowledgments\n",
    "\n",
    "The source of the scikit-learn demo:\n",
    "* http://scikit-learn.org/stable/tutorial/basic/tutorial.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
